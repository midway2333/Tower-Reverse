# Tower Reverse
基于推理时更新记忆参数的实验性质的自回归模型<br>
基于[Titans](https://arxiv.org/pdf/2501.00663v1)构建<br>
采用原论文的 MAG 架构, 并更换 Attention 为完整 Transformers-Decoder 结构<br>
Transformers-Decoder 来自[Tower2](https://github.com/midway2333/Tower2)<br>

## TODO
- [ ] 原论文的并行优化方法
